{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이벤트 날짜 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates = ['2017-01-25', # 트럼프 행정부가 EPA(환경보호청) 직원들에게 언론 보도, 블로그 업데이트, 소셜 미디어 게시를 금지\n",
    "               '2017-02-14', # 트럼프가 오바마 행정부 시절의 화석연료 산업 관련 금융 규제를 폐지하는 법안에 서명\n",
    "               '2017-02-28', # 트럼프가 오바마 행정부의 'Clean Water Rule'을 폐지하는 행정명령에 서명\n",
    "               '2017-03-28', # 트럼프가 오바마 행정부의 기후 정책들을 무효화하는 행정명령에 서명\n",
    "               '2017-04-28', # 트럼프가 해상 석유 및 가스 시추를 확대하는 행정명령에 서명\n",
    "               '2017-06-01', # 트럼프가 파리기후협정 탈퇴를 공식 발표\n",
    "               '2017-10-13', # 트럼프가 캐슬린 하트넷-화이트(기후변화에 대해 회의적인 입장을 가진 인물)를 백악관 환경품질위원회 의장으로 지명\n",
    "               '2018-06-19', # 트럼프 대통령은 '미국의 경제, 안보, 환경 이익을 증진하기 위한 해양 정책'에 관한 행정명령 13840에 서명\n",
    "               '2018-08-21', # 트럼프 행정부의 환경보호청(EPA)이 오바마 행정부의 'Clean Power Plan'을 폐기하고 이를 대체하는 'Affordable Clean Energy Rule' 제안서를 발표\n",
    "               '2019-04-12', # 트럼프가 주주들의 기후변화 관련 요구를 제한하는 행정명령에 서명\n",
    "               '2019-06-20', # 트럼프 행정부의 환경보호청(EPA)이 오바마 행정부의 주요 기후변화 정책인 'Clean Power Plan'을 폐지하고 이를 대체하는 'Affordable Clean Energy' 규칙을 최종 확정\n",
    "               '2019-11-04', # 트럼프가 유엔에 파리기후협정 탈퇴 의사를 공식 통보\n",
    "               '2020-06-05', # 트럼프 대통령은 대서양 유일의 해양 국립기념물인 Northeast Canyons and Seamounts Marine National Monument의 보호 조치를 철회하는 선언에 서명\n",
    "               '2020-11-01'] # 트럼프 대통령은 수압파쇄법(석유와 천연가스를 추출하는 특수한 시추 기술) 보호를 위한 행정명령에 서명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETF 데이터 다운"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# ESG ETF 데이터 불러오기\n",
    "esgu_etf = yf.download('ESGU', start='2016-01-01', end='2025-02-01')\n",
    "erth_etf = yf.download('ERTH', start='2016-01-01', end='2025-02-01')\n",
    "vde_etf = yf.download('VDE', start='2016-01-01', end='2025-02-01')\n",
    "nulg_etf = yf.download('NULG', start='2016-01-01', end='2025-02-01')\n",
    "tan_etf = yf.download('TAN', start='2016-01-01', end='2025-02-01')\n",
    "susa_etf = yf.download('SUSA', start='2016-01-01', end='2025-02-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "esgu_etf.to_csv('ESGU.csv', encoding='cp949')\n",
    "erth_etf.to_csv('ERTH.csv', encoding='cp949')\n",
    "vde_etf.to_csv('VDE.csv', encoding='cp949')\n",
    "nulg_etf.to_csv('NULG.csv', encoding='cp949')\n",
    "tan_etf.to_csv('TAN.csv', encoding='cp949')\n",
    "susa_etf.to_csv('SUSA.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S&P 500 데이터 다운"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "gspc_etf = yf.download('^GSPC', start='2016-01-01', end='2025-02-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "susa_etf.to_csv('^GSPC.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chica\\AppData\\Local\\Temp\\ipykernel_12332\\153757430.py:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(path, index_col=0, parse_dates=True)\n",
      "C:\\Users\\chica\\AppData\\Local\\Temp\\ipykernel_12332\\153757430.py:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(path, index_col=0, parse_dates=True)\n",
      "C:\\Users\\chica\\AppData\\Local\\Temp\\ipykernel_12332\\153757430.py:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(path, index_col=0, parse_dates=True)\n",
      "C:\\Users\\chica\\AppData\\Local\\Temp\\ipykernel_12332\\153757430.py:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(path, index_col=0, parse_dates=True)\n",
      "C:\\Users\\chica\\AppData\\Local\\Temp\\ipykernel_12332\\153757430.py:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(path, index_col=0, parse_dates=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S&amp;P500</th>\n",
       "      <th>ERTH</th>\n",
       "      <th>VDE</th>\n",
       "      <th>TAN</th>\n",
       "      <th>SUSA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <td>SUSA</td>\n",
       "      <td>ERTH</td>\n",
       "      <td>VDE</td>\n",
       "      <td>TAN</td>\n",
       "      <td>SUSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>35.96001052856445</td>\n",
       "      <td>23.39102554321289</td>\n",
       "      <td>60.45602798461914</td>\n",
       "      <td>28.320396423339844</td>\n",
       "      <td>35.96001052856445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>36.12253189086914</td>\n",
       "      <td>23.35863494873047</td>\n",
       "      <td>60.67426300048828</td>\n",
       "      <td>27.887813568115234</td>\n",
       "      <td>36.12253189086914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>35.54274368286133</td>\n",
       "      <td>22.89712905883789</td>\n",
       "      <td>58.31740188598633</td>\n",
       "      <td>27.34478187561035</td>\n",
       "      <td>35.54274368286133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       S&P500               ERTH                VDE  \\\n",
       "Price                                                                 \n",
       "Ticker                   SUSA               ERTH                VDE   \n",
       "Date                      NaN                NaN                NaN   \n",
       "2016-01-04  35.96001052856445  23.39102554321289  60.45602798461914   \n",
       "2016-01-05  36.12253189086914  23.35863494873047  60.67426300048828   \n",
       "2016-01-06  35.54274368286133  22.89712905883789  58.31740188598633   \n",
       "\n",
       "                           TAN               SUSA  \n",
       "Price                                              \n",
       "Ticker                     TAN               SUSA  \n",
       "Date                       NaN                NaN  \n",
       "2016-01-04  28.320396423339844  35.96001052856445  \n",
       "2016-01-05  27.887813568115234  36.12253189086914  \n",
       "2016-01-06   27.34478187561035  35.54274368286133  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 📌 사용할 파일 목록 (2016년 1월부터 데이터가 있는 ETF만)\n",
    "file_paths = {\n",
    "    \"S&P500\": \"^GSPC.csv\",\n",
    "    \"ERTH\": \"ERTH.csv\",\n",
    "    \"VDE\": \"VDE.csv\",\n",
    "    \"TAN\": \"TAN.csv\",\n",
    "    \"SUSA\": \"SUSA.csv\"\n",
    "}\n",
    "\n",
    "# 📌 데이터 불러오기\n",
    "dataframes = {}\n",
    "for etf, path in file_paths.items():\n",
    "    df = pd.read_csv(path, index_col=0, parse_dates=True)\n",
    "    df = df[['Close']]  # 종가만 사용\n",
    "    df.rename(columns={'Close': etf}, inplace=True)\n",
    "    dataframes[etf] = df\n",
    "\n",
    "# 📌 모든 데이터 합치기\n",
    "merged_data = pd.concat(dataframes.values(), axis=1, join=\"inner\")\n",
    "\n",
    "# ✅ 데이터 확인\n",
    "merged_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 변환된 데이터 샘플:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S&amp;P500</th>\n",
       "      <th>ERTH</th>\n",
       "      <th>VDE</th>\n",
       "      <th>TAN</th>\n",
       "      <th>SUSA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>35.960011</td>\n",
       "      <td>23.391026</td>\n",
       "      <td>60.456028</td>\n",
       "      <td>28.320396</td>\n",
       "      <td>35.960011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>36.122532</td>\n",
       "      <td>23.358635</td>\n",
       "      <td>60.674263</td>\n",
       "      <td>27.887814</td>\n",
       "      <td>36.122532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>35.542744</td>\n",
       "      <td>22.897129</td>\n",
       "      <td>58.317402</td>\n",
       "      <td>27.344782</td>\n",
       "      <td>35.542744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               S&P500       ERTH        VDE        TAN       SUSA\n",
       "Price                                                            \n",
       "Ticker            NaN        NaN        NaN        NaN        NaN\n",
       "Date              NaN        NaN        NaN        NaN        NaN\n",
       "2016-01-04  35.960011  23.391026  60.456028  28.320396  35.960011\n",
       "2016-01-05  36.122532  23.358635  60.674263  27.887814  36.122532\n",
       "2016-01-06  35.542744  22.897129  58.317402  27.344782  35.542744"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 📌 문자열 데이터를 float로 변환\n",
    "merged_data = merged_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 📌 변환 후 데이터 확인\n",
    "print(\"\\n📌 변환된 데이터 샘플:\")\n",
    "merged_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 정리된 데이터 샘플:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S&amp;P500</th>\n",
       "      <th>ERTH</th>\n",
       "      <th>VDE</th>\n",
       "      <th>TAN</th>\n",
       "      <th>SUSA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>35.542744</td>\n",
       "      <td>22.897129</td>\n",
       "      <td>58.317402</td>\n",
       "      <td>27.344782</td>\n",
       "      <td>35.542744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>34.897060</td>\n",
       "      <td>22.208927</td>\n",
       "      <td>56.862556</td>\n",
       "      <td>24.841322</td>\n",
       "      <td>34.897060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>34.435875</td>\n",
       "      <td>22.038897</td>\n",
       "      <td>56.142410</td>\n",
       "      <td>25.126642</td>\n",
       "      <td>34.435875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11</th>\n",
       "      <td>34.369984</td>\n",
       "      <td>21.731228</td>\n",
       "      <td>54.869431</td>\n",
       "      <td>24.224663</td>\n",
       "      <td>34.369984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-12</th>\n",
       "      <td>34.615952</td>\n",
       "      <td>22.006506</td>\n",
       "      <td>55.000355</td>\n",
       "      <td>23.700037</td>\n",
       "      <td>34.615952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               S&P500       ERTH        VDE        TAN       SUSA\n",
       "Date                                                             \n",
       "2016-01-06  35.542744  22.897129  58.317402  27.344782  35.542744\n",
       "2016-01-07  34.897060  22.208927  56.862556  24.841322  34.897060\n",
       "2016-01-08  34.435875  22.038897  56.142410  25.126642  34.435875\n",
       "2016-01-11  34.369984  21.731228  54.869431  24.224663  34.369984\n",
       "2016-01-12  34.615952  22.006506  55.000355  23.700037  34.615952"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 📌 첫 두 행 제거 (불필요한 행 제거)\n",
    "merged_data = merged_data.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# 📌 첫 번째 컬럼명을 'Date'로 설정\n",
    "merged_data.rename(columns={merged_data.columns[0]: \"Date\"}, inplace=True)\n",
    "\n",
    "# 📌 'Date' 컬럼을 날짜 형식으로 변환\n",
    "merged_data[\"Date\"] = pd.to_datetime(merged_data[\"Date\"])\n",
    "\n",
    "# 📌 'Date' 컬럼을 인덱스로 설정\n",
    "merged_data.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# ✅ 정리된 데이터 확인\n",
    "print(\"\\n📌 정리된 데이터 샘플:\")\n",
    "merged_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 일반수익률 샘플:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S&amp;P500</th>\n",
       "      <th>ERTH</th>\n",
       "      <th>VDE</th>\n",
       "      <th>TAN</th>\n",
       "      <th>SUSA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>-0.018166</td>\n",
       "      <td>-0.030056</td>\n",
       "      <td>-0.024947</td>\n",
       "      <td>-0.091552</td>\n",
       "      <td>-0.018166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>-0.013216</td>\n",
       "      <td>-0.007656</td>\n",
       "      <td>-0.012665</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>-0.013216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11</th>\n",
       "      <td>-0.001913</td>\n",
       "      <td>-0.013960</td>\n",
       "      <td>-0.022674</td>\n",
       "      <td>-0.035897</td>\n",
       "      <td>-0.001913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-12</th>\n",
       "      <td>0.007156</td>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>-0.021657</td>\n",
       "      <td>0.007156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-13</th>\n",
       "      <td>-0.023347</td>\n",
       "      <td>-0.031641</td>\n",
       "      <td>-0.020764</td>\n",
       "      <td>-0.034951</td>\n",
       "      <td>-0.023347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              S&P500      ERTH       VDE       TAN      SUSA\n",
       "Date                                                        \n",
       "2016-01-07 -0.018166 -0.030056 -0.024947 -0.091552 -0.018166\n",
       "2016-01-08 -0.013216 -0.007656 -0.012665  0.011486 -0.013216\n",
       "2016-01-11 -0.001913 -0.013960 -0.022674 -0.035897 -0.001913\n",
       "2016-01-12  0.007156  0.012667  0.002386 -0.021657  0.007156\n",
       "2016-01-13 -0.023347 -0.031641 -0.020764 -0.034951 -0.023347"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 📌 일반수익률(Arithmetic Return) 계산\n",
    "simple_returns = merged_data.pct_change().dropna()\n",
    "\n",
    "# ✅ 수익률 데이터 확인\n",
    "print(\"\\n📌 일반수익률 샘플:\")\n",
    "simple_returns.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 ETF별 α(알파), β(베타) 값:\n",
      "ERTH: α = -0.000010, β = 1.145360\n",
      "VDE: α = 0.000487, β = 1.332563\n",
      "TAN: α = -0.002848, β = 1.431612\n",
      "SUSA: α = 0.000000, β = 1.000000\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# 📌 추정 윈도우 설정\n",
    "estimation_start = \"2016-01-06\"\n",
    "estimation_end = \"2016-12-30\"\n",
    "\n",
    "# 📌 벤치마크(S&P500) 수익률\n",
    "market_returns = simple_returns[\"S&P500\"]\n",
    "\n",
    "# 📌 ETF별 α(알파), β(베타) 추정\n",
    "alpha_beta = {}\n",
    "\n",
    "for etf in simple_returns.columns:\n",
    "    if etf == \"S&P500\":\n",
    "        continue  # 벤치마크는 제외\n",
    "\n",
    "    etf_returns = simple_returns[etf]\n",
    "\n",
    "    # 📌 추정 기간의 데이터 선택\n",
    "    estimation_index = (market_returns.index >= estimation_start) & (market_returns.index <= estimation_end)\n",
    "    X = market_returns.loc[estimation_index]\n",
    "    Y = etf_returns.loc[estimation_index]\n",
    "\n",
    "    # 📌 OLS 회귀 분석\n",
    "    X = sm.add_constant(X)  # 상수항 추가 (α 추정)\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "\n",
    "    # 결과 저장\n",
    "    alpha, beta = model.params\n",
    "    alpha_beta[etf] = {\"alpha\": alpha, \"beta\": beta}\n",
    "\n",
    "# ✅ α, β 값 확인\n",
    "print(\"\\n📌 ETF별 α(알파), β(베타) 값:\")\n",
    "for etf, params in alpha_beta.items():\n",
    "    print(f\"{etf}: α = {params['alpha']:.6f}, β = {params['beta']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ ERTH에 2020-11-01 00:00:00 데이터가 없습니다. 해당 이벤트를 건너뜁니다.\n",
      "⚠️ VDE에 2020-11-01 00:00:00 데이터가 없습니다. 해당 이벤트를 건너뜁니다.\n",
      "⚠️ TAN에 2020-11-01 00:00:00 데이터가 없습니다. 해당 이벤트를 건너뜁니다.\n",
      "⚠️ SUSA에 2020-11-01 00:00:00 데이터가 없습니다. 해당 이벤트를 건너뜁니다.\n",
      "\n",
      "📌 이벤트별 비정상 수익률(AR) 샘플:\n",
      "📌 이벤트 2020-11-01:\n",
      "📌 이벤트 2017-01-25:\n",
      "  - ERTH:\n",
      "Date\n",
      "2017-01-18   -0.006779\n",
      "2017-01-19    0.002428\n",
      "2017-01-20    0.001382\n",
      "2017-01-23   -0.000725\n",
      "2017-01-24    0.002824\n",
      "2017-01-25    0.001872\n",
      "2017-01-26   -0.000688\n",
      "2017-01-27    0.005969\n",
      "2017-01-30   -0.005044\n",
      "2017-01-31    0.005211\n",
      "2017-02-01    0.001340\n",
      "dtype: float64\n",
      "  - VDE:\n",
      "Date\n",
      "2017-01-18   -0.005953\n",
      "2017-01-19    0.000427\n",
      "2017-01-20    0.001555\n",
      "2017-01-23   -0.015089\n",
      "2017-01-24    0.000077\n",
      "2017-01-25   -0.003634\n",
      "2017-01-26    0.006036\n",
      "2017-01-27   -0.008604\n",
      "2017-01-30   -0.010536\n",
      "2017-01-31   -0.001639\n",
      "2017-02-01   -0.008468\n",
      "dtype: float64\n",
      "  - TAN:\n",
      "Date\n",
      "2017-01-18   -0.003235\n",
      "2017-01-19    0.005290\n",
      "2017-01-20    0.002135\n",
      "2017-01-23   -0.005212\n",
      "2017-01-24   -0.013313\n",
      "2017-01-25    0.007294\n",
      "2017-01-26    0.003467\n",
      "2017-01-27   -0.001467\n",
      "2017-01-30   -0.008799\n",
      "2017-01-31    0.008332\n",
      "2017-02-01    0.006556\n",
      "dtype: float64\n",
      "  - SUSA:\n",
      "Date\n",
      "2017-01-18    0.000000e+00\n",
      "2017-01-19   -3.469447e-18\n",
      "2017-01-20    4.336809e-19\n",
      "2017-01-23    4.336809e-19\n",
      "2017-01-24    2.602085e-18\n",
      "2017-01-25    2.602085e-18\n",
      "2017-01-26   -2.602085e-18\n",
      "2017-01-27   -1.734723e-18\n",
      "2017-01-30   -3.469447e-18\n",
      "2017-01-31   -4.336809e-19\n",
      "2017-02-01   -4.336809e-19\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for event in event_dates:\n",
    "    event_day = pd.to_datetime(event)  # 이벤트 날짜를 Timestamp로 변환\n",
    "    \n",
    "    abnormal_returns[event] = {}\n",
    "\n",
    "    for etf in simple_returns.columns:\n",
    "        if etf == \"S&P500\":\n",
    "            continue  # 벤치마크 제외\n",
    "\n",
    "        etf_returns = simple_returns[etf]\n",
    "        market_returns_event = simple_returns[\"S&P500\"]\n",
    "\n",
    "        # 이벤트 날짜가 데이터의 인덱스에 있는지 확인\n",
    "        if event_day not in etf_returns.index:\n",
    "            print(f\"⚠️ {etf}에 {event_day} 데이터가 없습니다. 해당 이벤트를 건너뜁니다.\")\n",
    "            continue\n",
    "\n",
    "        # 이벤트 날짜의 인덱스를 찾기\n",
    "        event_idx = etf_returns.index.get_loc(event_day)\n",
    "\n",
    "        # 이벤트 이전 데이터가 충분한지 확인\n",
    "        if event_idx < 5:\n",
    "            print(f\"⚠️ {etf}에서 {event_day} 이전 데이터가 충분하지 않습니다. 해당 이벤트를 건너뜁니다.\")\n",
    "            continue\n",
    "\n",
    "        # 전후 5일 (총 11일)의 데이터 선택\n",
    "        date_range = etf_returns.index[event_idx - 5: event_idx + 6]\n",
    "\n",
    "        # 유효한 날짜만 선택 (시장 데이터와 일치하는 날짜만 필터링)\n",
    "        valid_dates = date_range[date_range.isin(market_returns_event.index)]\n",
    "\n",
    "        # 예상 수익률 계산\n",
    "        if etf in alpha_beta:\n",
    "            alpha = alpha_beta[etf][\"alpha\"]\n",
    "            beta = alpha_beta[etf][\"beta\"]\n",
    "            expected_return = alpha + beta * market_returns_event.loc[valid_dates]\n",
    "\n",
    "            # 비정상 수익률 (AR) 계산\n",
    "            abnormal_return = etf_returns.loc[valid_dates] - expected_return\n",
    "            abnormal_returns[event][etf] = abnormal_return\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n📌 이벤트별 비정상 수익률(AR) 샘플:\")\n",
    "for event, etf_data in list(abnormal_returns.items())[:2]:  # 처음 2개 이벤트만 출력\n",
    "    print(f\"📌 이벤트 {event}:\")\n",
    "    for etf, ar in etf_data.items():\n",
    "        print(f\"  - {etf}:\\n{ar}\")  # 전체 데이터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 이벤트별 누적 비정상 수익률(CAR) 샘플:\n",
      "📌 이벤트 2017-01-25:\n",
      "  - ERTH:\n",
      "Date\n",
      "2017-01-18   -0.006779\n",
      "2017-01-19   -0.004351\n",
      "2017-01-20   -0.002969\n",
      "2017-01-23   -0.003694\n",
      "2017-01-24   -0.000870\n",
      "2017-01-25    0.001002\n",
      "2017-01-26    0.000315\n",
      "2017-01-27    0.006284\n",
      "2017-01-30    0.001239\n",
      "2017-01-31    0.006451\n",
      "2017-02-01    0.007790\n",
      "dtype: float64\n",
      "  - VDE:\n",
      "Date\n",
      "2017-01-18   -0.005953\n",
      "2017-01-19   -0.005526\n",
      "2017-01-20   -0.003971\n",
      "2017-01-23   -0.019060\n",
      "2017-01-24   -0.018983\n",
      "2017-01-25   -0.022617\n",
      "2017-01-26   -0.016581\n",
      "2017-01-27   -0.025185\n",
      "2017-01-30   -0.035721\n",
      "2017-01-31   -0.037359\n",
      "2017-02-01   -0.045827\n",
      "dtype: float64\n",
      "  - TAN:\n",
      "Date\n",
      "2017-01-18   -0.003235\n",
      "2017-01-19    0.002056\n",
      "2017-01-20    0.004191\n",
      "2017-01-23   -0.001021\n",
      "2017-01-24   -0.014335\n",
      "2017-01-25   -0.007040\n",
      "2017-01-26   -0.003574\n",
      "2017-01-27   -0.005041\n",
      "2017-01-30   -0.013840\n",
      "2017-01-31   -0.005507\n",
      "2017-02-01    0.001049\n",
      "dtype: float64\n",
      "  - SUSA:\n",
      "Date\n",
      "2017-01-18    0.000000e+00\n",
      "2017-01-19   -3.469447e-18\n",
      "2017-01-20   -3.035766e-18\n",
      "2017-01-23   -2.602085e-18\n",
      "2017-01-24    0.000000e+00\n",
      "2017-01-25    2.602085e-18\n",
      "2017-01-26    0.000000e+00\n",
      "2017-01-27   -1.734723e-18\n",
      "2017-01-30   -5.204170e-18\n",
      "2017-01-31   -5.637851e-18\n",
      "2017-02-01   -6.071532e-18\n",
      "dtype: float64\n",
      "📌 이벤트 2017-02-14:\n",
      "  - ERTH:\n",
      "Date\n",
      "2017-02-07    0.000507\n",
      "2017-02-08   -0.008151\n",
      "2017-02-09   -0.009724\n",
      "2017-02-10   -0.008750\n",
      "2017-02-13   -0.012706\n",
      "2017-02-14   -0.021287\n",
      "2017-02-15   -0.022151\n",
      "2017-02-16   -0.020915\n",
      "2017-02-17   -0.020418\n",
      "2017-02-21   -0.022456\n",
      "2017-02-22   -0.026008\n",
      "dtype: float64\n",
      "  - VDE:\n",
      "Date\n",
      "2017-02-07   -0.016871\n",
      "2017-02-08   -0.019905\n",
      "2017-02-09   -0.019971\n",
      "2017-02-10   -0.017140\n",
      "2017-02-13   -0.024310\n",
      "2017-02-14   -0.025429\n",
      "2017-02-15   -0.038785\n",
      "2017-02-16   -0.052759\n",
      "2017-02-17   -0.062016\n",
      "2017-02-21   -0.064515\n",
      "2017-02-22   -0.081035\n",
      "dtype: float64\n",
      "  - TAN:\n",
      "Date\n",
      "2017-02-07   -0.005260\n",
      "2017-02-08   -0.001855\n",
      "2017-02-09   -0.006760\n",
      "2017-02-10    0.012668\n",
      "2017-02-13    0.023579\n",
      "2017-02-14    0.027042\n",
      "2017-02-15    0.042393\n",
      "2017-02-16    0.038149\n",
      "2017-02-17    0.043222\n",
      "2017-02-21    0.059117\n",
      "2017-02-22    0.049892\n",
      "dtype: float64\n",
      "  - SUSA:\n",
      "Date\n",
      "2017-02-07   -4.336809e-19\n",
      "2017-02-08   -4.336809e-19\n",
      "2017-02-09    3.035766e-18\n",
      "2017-02-10    3.469447e-18\n",
      "2017-02-13    5.204170e-18\n",
      "2017-02-14    6.071532e-18\n",
      "2017-02-15    7.806256e-18\n",
      "2017-02-16    6.938894e-18\n",
      "2017-02-17    7.155734e-18\n",
      "2017-02-21    9.757820e-18\n",
      "2017-02-22    8.890458e-18\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# CAR을 저장할 딕셔너리 초기화\n",
    "cumulative_abnormal_returns = {}\n",
    "\n",
    "# 이벤트별로 CAR 계산\n",
    "for event, etf_data in abnormal_returns.items():\n",
    "    cumulative_abnormal_returns[event] = {}\n",
    "\n",
    "    for etf, abnormal_return in etf_data.items():\n",
    "        # 누적 비정상 수익률 (CAR) 계산\n",
    "        car = abnormal_return.cumsum()  # AR을 누적하여 CAR 계산\n",
    "        cumulative_abnormal_returns[event][etf] = car\n",
    "\n",
    "# ✅ CAR 샘플 확인\n",
    "print(\"\\n📌 이벤트별 누적 비정상 수익률(CAR) 샘플:\")\n",
    "for event, etf_data in list(cumulative_abnormal_returns.items())[:2]:  # 처음 2개 이벤트만 출력\n",
    "    print(f\"📌 이벤트 {event}:\")\n",
    "    for etf, car in etf_data.items():\n",
    "        print(f\"  - {etf}:\\n{car}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 이벤트 2017-01-25, ERTH - Shapiro-Wilk p-value: 0.521661\n",
      "📌 이벤트 2017-01-25, ERTH - t-test p-value: 0.787204\n",
      "📌 이벤트 2017-01-25, ERTH - Wilcoxon test p-value: 0.831055\n",
      "📌 이벤트 2017-01-25, VDE - Shapiro-Wilk p-value: 0.487212\n",
      "📌 이벤트 2017-01-25, VDE - t-test p-value: 0.000414\n",
      "📌 이벤트 2017-01-25, VDE - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2017-01-25, TAN - Shapiro-Wilk p-value: 0.500177\n",
      "📌 이벤트 2017-01-25, TAN - t-test p-value: 0.041058\n",
      "📌 이벤트 2017-01-25, TAN - Wilcoxon test p-value: 0.053711\n",
      "📌 이벤트 2017-01-25, SUSA - Shapiro-Wilk p-value: 0.622382\n",
      "📌 이벤트 2017-01-25, SUSA - t-test p-value: 0.020454\n",
      "📌 이벤트 2017-01-25, SUSA - Wilcoxon test p-value: 0.029773\n",
      "📌 이벤트 2017-02-14, ERTH - Shapiro-Wilk p-value: 0.180315\n",
      "📌 이벤트 2017-02-14, ERTH - t-test p-value: 0.000094\n",
      "📌 이벤트 2017-02-14, ERTH - Wilcoxon test p-value: 0.001953\n",
      "📌 이벤트 2017-02-14, VDE - Shapiro-Wilk p-value: 0.049884\n",
      "📌 이벤트 2017-02-14, VDE - t-test p-value: 0.000236\n",
      "📌 이벤트 2017-02-14, VDE - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2017-02-14, TAN - Shapiro-Wilk p-value: 0.369419\n",
      "📌 이벤트 2017-02-14, TAN - t-test p-value: 0.004355\n",
      "📌 이벤트 2017-02-14, TAN - Wilcoxon test p-value: 0.013672\n",
      "📌 이벤트 2017-02-14, SUSA - Shapiro-Wilk p-value: 0.350827\n",
      "📌 이벤트 2017-02-14, SUSA - t-test p-value: 0.000535\n",
      "📌 이벤트 2017-02-14, SUSA - Wilcoxon test p-value: 0.004883\n",
      "📌 이벤트 2017-02-28, ERTH - Shapiro-Wilk p-value: 0.134626\n",
      "📌 이벤트 2017-02-28, ERTH - t-test p-value: 0.000930\n",
      "📌 이벤트 2017-02-28, ERTH - Wilcoxon test p-value: 0.004883\n",
      "📌 이벤트 2017-02-28, VDE - Shapiro-Wilk p-value: 0.163399\n",
      "📌 이벤트 2017-02-28, VDE - t-test p-value: 0.000004\n",
      "📌 이벤트 2017-02-28, VDE - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2017-02-28, TAN - Shapiro-Wilk p-value: 0.288145\n",
      "📌 이벤트 2017-02-28, TAN - t-test p-value: 0.033784\n",
      "📌 이벤트 2017-02-28, TAN - Wilcoxon test p-value: 0.083008\n",
      "📌 이벤트 2017-02-28, SUSA - Shapiro-Wilk p-value: 0.749652\n",
      "📌 이벤트 2017-02-28, SUSA - t-test p-value: 0.997640\n",
      "📌 이벤트 2017-02-28, SUSA - Wilcoxon test p-value: 0.831055\n",
      "📌 이벤트 2017-03-28, ERTH - Shapiro-Wilk p-value: 0.998518\n",
      "📌 이벤트 2017-03-28, ERTH - t-test p-value: 0.003761\n",
      "📌 이벤트 2017-03-28, ERTH - Wilcoxon test p-value: 0.006836\n",
      "📌 이벤트 2017-03-28, VDE - Shapiro-Wilk p-value: 0.490964\n",
      "📌 이벤트 2017-03-28, VDE - t-test p-value: 0.182179\n",
      "📌 이벤트 2017-03-28, VDE - Wilcoxon test p-value: 0.240234\n",
      "📌 이벤트 2017-03-28, TAN - Shapiro-Wilk p-value: 0.096655\n",
      "📌 이벤트 2017-03-28, TAN - t-test p-value: 0.126723\n",
      "📌 이벤트 2017-03-28, TAN - Wilcoxon test p-value: 0.147461\n",
      "📌 이벤트 2017-03-28, SUSA - Shapiro-Wilk p-value: 0.092837\n",
      "📌 이벤트 2017-03-28, SUSA - t-test p-value: 0.000000\n",
      "📌 이벤트 2017-03-28, SUSA - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2017-04-28, ERTH - Shapiro-Wilk p-value: 0.874379\n",
      "📌 이벤트 2017-04-28, ERTH - t-test p-value: 0.000015\n",
      "📌 이벤트 2017-04-28, ERTH - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2017-04-28, VDE - Shapiro-Wilk p-value: 0.834053\n",
      "📌 이벤트 2017-04-28, VDE - t-test p-value: 0.000194\n",
      "📌 이벤트 2017-04-28, VDE - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2017-04-28, TAN - Shapiro-Wilk p-value: 0.329023\n",
      "📌 이벤트 2017-04-28, TAN - t-test p-value: 0.002685\n",
      "📌 이벤트 2017-04-28, TAN - Wilcoxon test p-value: 0.001953\n",
      "📌 이벤트 2017-04-28, SUSA - Shapiro-Wilk p-value: 0.868171\n",
      "📌 이벤트 2017-04-28, SUSA - t-test p-value: 0.000657\n",
      "📌 이벤트 2017-04-28, SUSA - Wilcoxon test p-value: 0.001953\n",
      "📌 이벤트 2017-06-01, ERTH - Shapiro-Wilk p-value: 0.424472\n",
      "📌 이벤트 2017-06-01, ERTH - t-test p-value: 0.000225\n",
      "📌 이벤트 2017-06-01, ERTH - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2017-06-01, VDE - Shapiro-Wilk p-value: 0.235942\n",
      "📌 이벤트 2017-06-01, VDE - t-test p-value: 0.000012\n",
      "📌 이벤트 2017-06-01, VDE - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2017-06-01, TAN - Shapiro-Wilk p-value: 0.320387\n",
      "📌 이벤트 2017-06-01, TAN - t-test p-value: 0.000570\n",
      "📌 이벤트 2017-06-01, TAN - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2017-06-01, SUSA - Shapiro-Wilk p-value: 0.364417\n",
      "📌 이벤트 2017-06-01, SUSA - t-test p-value: 0.000572\n",
      "📌 이벤트 2017-06-01, SUSA - Wilcoxon test p-value: 0.001953\n",
      "📌 이벤트 2017-10-13, ERTH - Shapiro-Wilk p-value: 0.763685\n",
      "📌 이벤트 2017-10-13, ERTH - t-test p-value: 0.118414\n",
      "📌 이벤트 2017-10-13, ERTH - Wilcoxon test p-value: 0.123047\n",
      "📌 이벤트 2017-10-13, VDE - Shapiro-Wilk p-value: 0.328238\n",
      "📌 이벤트 2017-10-13, VDE - t-test p-value: 0.000292\n",
      "📌 이벤트 2017-10-13, VDE - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2017-10-13, TAN - Shapiro-Wilk p-value: 0.410616\n",
      "📌 이벤트 2017-10-13, TAN - t-test p-value: 0.001524\n",
      "📌 이벤트 2017-10-13, TAN - Wilcoxon test p-value: 0.002930\n",
      "📌 이벤트 2017-10-13, SUSA - Shapiro-Wilk p-value: 0.456746\n",
      "📌 이벤트 2017-10-13, SUSA - t-test p-value: 0.000003\n",
      "📌 이벤트 2017-10-13, SUSA - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2018-06-19, ERTH - Shapiro-Wilk p-value: 0.586128\n",
      "📌 이벤트 2018-06-19, ERTH - t-test p-value: 0.000209\n",
      "📌 이벤트 2018-06-19, ERTH - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2018-06-19, VDE - Shapiro-Wilk p-value: 0.830634\n",
      "📌 이벤트 2018-06-19, VDE - t-test p-value: 0.002066\n",
      "📌 이벤트 2018-06-19, VDE - Wilcoxon test p-value: 0.002930\n",
      "📌 이벤트 2018-06-19, TAN - Shapiro-Wilk p-value: 0.813826\n",
      "📌 이벤트 2018-06-19, TAN - t-test p-value: 0.000066\n",
      "📌 이벤트 2018-06-19, TAN - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2018-06-19, SUSA - Shapiro-Wilk p-value: 0.306015\n",
      "📌 이벤트 2018-06-19, SUSA - t-test p-value: 0.001140\n",
      "📌 이벤트 2018-06-19, SUSA - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2018-08-21, ERTH - Shapiro-Wilk p-value: 0.192520\n",
      "📌 이벤트 2018-08-21, ERTH - t-test p-value: 0.535257\n",
      "📌 이벤트 2018-08-21, ERTH - Wilcoxon test p-value: 0.519531\n",
      "📌 이벤트 2018-08-21, VDE - Shapiro-Wilk p-value: 0.832824\n",
      "📌 이벤트 2018-08-21, VDE - t-test p-value: 0.000014\n",
      "📌 이벤트 2018-08-21, VDE - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2018-08-21, TAN - Shapiro-Wilk p-value: 0.187924\n",
      "📌 이벤트 2018-08-21, TAN - t-test p-value: 0.021998\n",
      "📌 이벤트 2018-08-21, TAN - Wilcoxon test p-value: 0.041992\n",
      "📌 이벤트 2018-08-21, SUSA - Shapiro-Wilk p-value: 0.821899\n",
      "📌 이벤트 2018-08-21, SUSA - t-test p-value: 0.020926\n",
      "📌 이벤트 2018-08-21, SUSA - Wilcoxon test p-value: 0.024414\n",
      "📌 이벤트 2019-04-12, ERTH - Shapiro-Wilk p-value: 0.013184\n",
      "📌 이벤트 2019-04-12, ERTH - t-test p-value: 0.007174\n",
      "📌 이벤트 2019-04-12, ERTH - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2019-04-12, VDE - Shapiro-Wilk p-value: 0.655113\n",
      "📌 이벤트 2019-04-12, VDE - t-test p-value: 0.053706\n",
      "📌 이벤트 2019-04-12, VDE - Wilcoxon test p-value: 0.101562\n",
      "📌 이벤트 2019-04-12, TAN - Shapiro-Wilk p-value: 0.179821\n",
      "📌 이벤트 2019-04-12, TAN - t-test p-value: 0.000164\n",
      "📌 이벤트 2019-04-12, TAN - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2019-04-12, SUSA - Shapiro-Wilk p-value: 0.398620\n",
      "📌 이벤트 2019-04-12, SUSA - t-test p-value: 0.009325\n",
      "📌 이벤트 2019-04-12, SUSA - Wilcoxon test p-value: 0.013672\n",
      "📌 이벤트 2019-06-20, ERTH - Shapiro-Wilk p-value: 0.362462\n",
      "📌 이벤트 2019-06-20, ERTH - t-test p-value: 0.960144\n",
      "📌 이벤트 2019-06-20, ERTH - Wilcoxon test p-value: 0.577148\n",
      "📌 이벤트 2019-06-20, VDE - Shapiro-Wilk p-value: 0.513013\n",
      "📌 이벤트 2019-06-20, VDE - t-test p-value: 0.000993\n",
      "📌 이벤트 2019-06-20, VDE - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2019-06-20, TAN - Shapiro-Wilk p-value: 0.611178\n",
      "📌 이벤트 2019-06-20, TAN - t-test p-value: 0.000023\n",
      "📌 이벤트 2019-06-20, TAN - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2019-06-20, SUSA - Shapiro-Wilk p-value: 0.794479\n",
      "📌 이벤트 2019-06-20, SUSA - t-test p-value: 0.014630\n",
      "📌 이벤트 2019-06-20, SUSA - Wilcoxon test p-value: 0.018555\n",
      "📌 이벤트 2019-11-04, ERTH - Shapiro-Wilk p-value: 0.279773\n",
      "📌 이벤트 2019-11-04, ERTH - t-test p-value: 0.095688\n",
      "📌 이벤트 2019-11-04, ERTH - Wilcoxon test p-value: 0.174805\n",
      "📌 이벤트 2019-11-04, VDE - Shapiro-Wilk p-value: 0.743013\n",
      "📌 이벤트 2019-11-04, VDE - t-test p-value: 0.000466\n",
      "📌 이벤트 2019-11-04, VDE - Wilcoxon test p-value: 0.002930\n",
      "📌 이벤트 2019-11-04, TAN - Shapiro-Wilk p-value: 0.147600\n",
      "📌 이벤트 2019-11-04, TAN - t-test p-value: 0.000043\n",
      "📌 이벤트 2019-11-04, TAN - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2019-11-04, SUSA - Shapiro-Wilk p-value: 0.233979\n",
      "📌 이벤트 2019-11-04, SUSA - t-test p-value: 0.000042\n",
      "📌 이벤트 2019-11-04, SUSA - Wilcoxon test p-value: 0.001953\n",
      "📌 이벤트 2020-06-05, ERTH - Shapiro-Wilk p-value: 0.372855\n",
      "📌 이벤트 2020-06-05, ERTH - t-test p-value: 0.000075\n",
      "📌 이벤트 2020-06-05, ERTH - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2020-06-05, VDE - Shapiro-Wilk p-value: 0.364721\n",
      "📌 이벤트 2020-06-05, VDE - t-test p-value: 0.005774\n",
      "📌 이벤트 2020-06-05, VDE - Wilcoxon test p-value: 0.002930\n",
      "📌 이벤트 2020-06-05, TAN - Shapiro-Wilk p-value: 0.123249\n",
      "📌 이벤트 2020-06-05, TAN - t-test p-value: 0.000008\n",
      "📌 이벤트 2020-06-05, TAN - Wilcoxon test p-value: 0.000977\n",
      "📌 이벤트 2020-06-05, SUSA - Shapiro-Wilk p-value: 0.737087\n",
      "📌 이벤트 2020-06-05, SUSA - t-test p-value: 0.023486\n",
      "📌 이벤트 2020-06-05, SUSA - Wilcoxon test p-value: 0.032227\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro, ttest_1samp, wilcoxon\n",
    "\n",
    "# 📌 CAR의 정규성 검정 및 t-검정 / 윌콕슨 검정\n",
    "for event, etf_data in event_car.items():\n",
    "    for etf, car in etf_data.items():\n",
    "        # 📌 정규성 검정 (Shapiro-Wilk Test)\n",
    "        stat, p_value = shapiro(car)\n",
    "        print(f\"📌 이벤트 {event}, {etf} - Shapiro-Wilk p-value: {p_value:.6f}\")\n",
    "\n",
    "        # 📌 t-검정 (귀무가설: CAR = 0)\n",
    "        t_stat, t_p_value = ttest_1samp(car, 0)\n",
    "        print(f\"📌 이벤트 {event}, {etf} - t-test p-value: {t_p_value:.6f}\")\n",
    "\n",
    "        # 📌 윌콕슨 검정 (귀무가설: CAR = 0)\n",
    "        w_stat, w_p_value = wilcoxon(car)\n",
    "        print(f\"📌 이벤트 {event}, {etf} - Wilcoxon test p-value: {w_p_value:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
